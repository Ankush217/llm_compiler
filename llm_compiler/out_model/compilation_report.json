{
  "spec": {
    "name": "debug-2k-transformer",
    "template": "decoder_only",
    "vocab_size": 32,
    "context_length": 16,
    "num_layers": 1,
    "hidden_size": 16,
    "intermediate_size": 32,
    "num_heads": 2,
    "num_kv_heads": null,
    "head_dim": null,
    "target_params": null,
    "explicit_dims": {
      "num_layers": 1,
      "hidden_size": 16,
      "intermediate_size": 32,
      "num_heads": 2
    },
    "target_tolerance": 0.1,
    "attention": "gqa",
    "norm": "rmsnorm",
    "activation": "relu",
    "positional_encoding": "rope",
    "tokenizer": "unigram",
    "weight_format": "safetensors",
    "backend": "pytorch_training",
    "rope_theta": 10000.0,
    "rope_scaling_factor": null,
    "alibi_max_bias": 8.0,
    "sliding_window_size": null,
    "tie_word_embeddings": true,
    "tie_embeddings": true,
    "gradient_checkpointing": false,
    "precision": "float32",
    "quantize": null,
    "quantize_bits": 16,
    "_validated": false
  },
  "steps": [
    {
      "step": "template_selection",
      "template": "decoder_only_v1",
      "status": "success"
    },
    {
      "step": "spec_validation",
      "status": "success"
    },
    {
      "step": "dimension_solving",
      "status": "success",
      "parameters": 3008,
      "warnings": []
    },
    {
      "step": "ir_generation",
      "status": "success",
      "nodes": 17,
      "tensors": 18
    },
    {
      "step": "parameter_accounting",
      "status": "success",
      "parameters_ir": 2976,
      "template_estimate": 3008,
      "relative_diff": 0.010638297872340425
    },
    {
      "step": "finalization",
      "status": "success"
    }
  ],
  "success": true,
  "output_dir": "/Users/apple/alwork/llm_compiler/out_model",
  "files": [
    {
      "path": "model/llmc-decoder-only-0m-relu.py",
      "type": "code",
      "size": 20278
    },
    {
      "path": "model/config.py",
      "type": "code",
      "size": 499
    },
    {
      "path": "model/__init__.py",
      "type": "code",
      "size": 188
    },
    {
      "path": "model/setup.py",
      "type": "code",
      "size": 293
    },
    {
      "path": "model/test_llmc-decoder-only-0m-relu.py",
      "type": "code",
      "size": 670
    },
    {
      "path": "weights/manifest.json",
      "type": "manifest",
      "size": 857
    }
  ],
  "solution": {
    "dimensions": {
      "hidden_size": 16,
      "num_heads": 2,
      "num_kv_heads": 1,
      "intermediate_size": 32,
      "num_layers": 1,
      "total_params": 2976,
      "None": 1,
      "vocab_size": 32,
      "context_length": 16,
      "head_dim": 8
    },
    "actual_params": 2976,
    "target_params": null,
    "warnings": [],
    "constraints_satisfied": true,
    "param_source": "ir_graph"
  },
  "notes": [
    "Template estimate differs from IR (3,008 vs 2,976); IR is canonical."
  ],
  "model_name": "llmc-decoder-only-0m-relu",
  "model_dir": "model",
  "weights_dir": "weights",
  "total_files": 6,
  "compilation_time": "N/A"
}